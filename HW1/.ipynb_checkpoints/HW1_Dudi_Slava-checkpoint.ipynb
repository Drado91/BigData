{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87f7401",
   "metadata": {},
   "source": [
    "ID #1: 319238119\n",
    "\n",
    "ID #2: 305560070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77afdbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Create local CSV file “mydata.csv” with 1000000 rows with columns (id, fruit, price, color). Use\n",
    "random value for rows, where fruit has one of the values ['Orange', 'Grape', 'Apple', 'Banana',\n",
    "'Pineapple', 'Avocado'] and colors are ['Red', 'Green', 'Yellow', 'Blue']. Price should be random\n",
    "integer between 10 and 100. Filed id should be an index number starting from 1.\n",
    "\n",
    "'''\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "index = range(1, 1000001)\n",
    "price = range(10, 101)\n",
    "\n",
    "fruit = [random.choice(['Orange', 'Grape', 'Apple', 'Banana', 'Pineapple', 'Avocado']) for i in index]\n",
    "color = [random.choice(['Red', 'Green', 'Yellow', 'Blue']) for i in index]\n",
    "price = [random.choice(price) for i in index]\n",
    "\n",
    "df = pd.DataFrame({'id' : index, 'fruit' : fruit, 'price' : price, 'color' : color})\n",
    "df.to_csv('mydata.csv', index=False)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d450173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Task 1 Question 1 \n",
    "\n",
    "Write Python code to create SQLite database “mydb.db” and create a table “mydata” with the schema of the “mydata.csv”\n",
    "'''\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(r'mydb.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute('CREATE TABLE mydata (id integer, fruit text, color text, price integer);')\n",
    "conn.close()\n",
    "\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c88e4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 1 Question 2\n",
    "\n",
    "Write Python code to load “mydata.csv” into “mydata” table.\n",
    "'''\n",
    "\n",
    "import csv, sqlite3\n",
    "\n",
    "conn = sqlite3.connect(r\"mydb.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "with open('mydata.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        cur.execute('INSERT INTO mydata (id, fruit, price, color) VALUES (?, ?, ?, ?);', row)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab143717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_price_of_grapes = [(54.96414352228306,)]\n",
      "count_of_blue_oranges = [(41364,)]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 1 Question 3\n",
    "\n",
    "Write 2 different SQL statements  with different conditions to retrieve different rows.\n",
    "Explain which parts of the statement are predicate and which parts are projection.\n",
    "'''\n",
    "\n",
    "import csv, sqlite3\n",
    "\n",
    "conn = sqlite3.connect(r'mydb.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 'SELECT AVG(price)' is the projection and 'WHERE fruit = \"Grape\"' is the predicate\n",
    "average_price_of_grapes_query = ''' SELECT AVG(price) \n",
    "                                    FROM mydata \n",
    "                                    WHERE fruit = \"Grape\"; '''\n",
    "\n",
    "cur.execute(average_price_of_grapes_query)\n",
    "result = cur.fetchall()\n",
    "print('average_price_of_grapes =', result)\n",
    "\n",
    "# 'SELECT COUNT(id)' is the projection and 'WHERE fruit = \"Orange\" AND color = \"Blue\"' is the predicate\n",
    "count_of_blue_oranges_query = ''' SELECT COUNT(id) \n",
    "                                FROM mydata\n",
    "                                WHERE fruit = \"Orange\" AND color = \"Blue\"; '''\n",
    "\n",
    "cur.execute(count_of_blue_oranges_query)\n",
    "result = cur.fetchall()\n",
    "print('count_of_blue_oranges =', result)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c23df4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Task 2 Question 1\n",
    "\n",
    "Write Python program that reads “mydata.csv” file and count number of lines.\n",
    "'''\n",
    "\n",
    "with open('mydata.csv','r') as f:\n",
    "    row_count = sum(1 for row in f)\n",
    "    \n",
    "row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc9de1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 2 Question 2\n",
    "\n",
    "By using PyArrow, create Parquet file from the “mydata.csv”. Name Parquet file as “mydatapyarrow.parquet”.\n",
    "'''\n",
    "\n",
    "import pyarrow.csv as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "table = pa.read_csv('mydata.csv')\n",
    "pq.write_to_dataset(table=table,\n",
    "                    root_path='mydatapyarrow.parquet')\n",
    "\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f930905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 2 Question 3\n",
    "\n",
    "By using Dask, create Parquet file from the “mydata.csv”. Name Parquet file as “mydatadask.parquet”.\n",
    "'''\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('mydata.csv')\n",
    "df.to_parquet('mydatadask.parquet')\n",
    "\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7419269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 2 Question 4\n",
    "\n",
    "By using Pandas, create Parquet file from the “mydata.csv”. Name Parquet file as “mydatapandas.parquet”.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('mydata.csv')\n",
    "df.to_parquet('mydatapandas.parquet')\n",
    "\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b17aafb",
   "metadata": {},
   "source": [
    "#### Task 2 Question 5\n",
    "\n",
    "Examine generated Parquet files.  Why do you think Dask generated Parquet file differently than PyArrow and Pandas? \n",
    "What might be explanation for this?\n",
    "\n",
    "#### Answer\n",
    "\n",
    "Unlike PyArrow and Pandas, Dask was designed with having to process multiple input files in mind. Dask allows patitioning\n",
    "the input data into multiple .parquet files named \"part.i.parquet\" while 'i' stands for the partition number. This\n",
    "effectively allows Dask to read/write/perform computations on multiple files in parallel in order to improve performance.\n",
    "\n",
    "Also, when the .parquet files are generated with Dask, additional files are created for metadata storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ebd94ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11367204.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Task 3 Question 1\n",
    "\n",
    "Write Python code that calculates size of “mydata.csv” in bytes.\n",
    "Define an integer variable “middle” which is the size of “mydata.csv”  divided by 2. \n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "middle = os.path.getsize('mydata.csv') / 2\n",
    "\n",
    "middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3752d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First chunk lines count: 502467\n",
      "Last chunk lines count: 497535\n",
      "1000002\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 3 Question 2\n",
    "\n",
    "Write a Python function first_chunk that count number of rows by reading the byte range of the CSV file, \n",
    "from 0 till the “middle”. Write a function last_chunk that count number of rows by reading byte range of\n",
    "CSV file from the “middle”+1 till the end of the file.\n",
    "'''\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "def first_chunk(middle):\n",
    "    with open('mydata.csv','rb') as f:\n",
    "        byte_stream = f.read(math.floor(middle)).decode(encoding='utf-8')\n",
    "        return byte_stream.count('\\n') if byte_stream[math.floor(middle) - 1] == '\\n' else byte_stream.count('\\n') + 1 \n",
    "\n",
    "def last_chunk(middle):\n",
    "    with open('mydata.csv','rb') as f:\n",
    "        f.seek(math.floor(middle), 0)\n",
    "        byte_stream = f.read(math.ceil(middle)).decode(encoding='utf-8')\n",
    "        return byte_stream.count('\\n') - 1 if byte_stream[0] == '\\n' else byte_stream.count('\\n')\n",
    "\n",
    "middle = os.path.getsize('mydata.csv') / 2\n",
    "print('First chunk lines count:', first_chunk(middle))\n",
    "print(\"Last chunk lines count:\", last_chunk(middle))\n",
    "print(first_chunk(middle) + last_chunk(middle))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add371e",
   "metadata": {},
   "source": [
    "#### Task 3 Question 3\n",
    "\n",
    "Explain why total number of lines from the first chunk and second chunk is larger than\n",
    "the number of lines calculated in the step (1) of Task 2.\n",
    "\n",
    "#### Answer\n",
    "\n",
    "Because for most files the partition will occur right in the middle of a line which as a result will be counted by both first_chunk and last_chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2468f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First chunk lines count: 502467\n",
      "Last chunk lines count: 497534\n",
      "1000001\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 3 Question 4\n",
    "\n",
    "Suggest an algorithm to resolve the issue from the step (3) and implement it.\n",
    "'''\n",
    "\n",
    "'''\n",
    "The extra line problem occurs when the split is performed in the middle of a line (first chunk doesn't end in '\\n'\n",
    "and last chunk doesn't start with '\\n'). We're are going to divide the file size by 2 and then scan the byte stream\n",
    "until the next newline char and set middle to be the index of the char after that. This way we ensure a line is not\n",
    "getting split in the middle.\n",
    "\n",
    "We read more bytes than we wanted in the first chunk, but given that we know the upper length limit for a line in\n",
    "mydata.csv we want want to do that.\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "def first_chunk(chunk_size):\n",
    "    with open('mydata.csv','rb') as f:\n",
    "        byte_stream = f.read(chunk_size).decode(encoding='utf-8')\n",
    "        return byte_stream.count('\\n')\n",
    "\n",
    "def last_chunk(chunk_size):\n",
    "    with open('mydata.csv','rb') as f:\n",
    "        last_chunk_size = os.path.getsize('mydata.csv') - chunk_size\n",
    "        f.seek(chunk_size, 0)\n",
    "        byte_stream = f.read(last_chunk_size).decode(encoding='utf-8')\n",
    "        # We ignore the first newline char.\n",
    "        return byte_stream.count('\\n')\n",
    "\n",
    "middle = int(os.path.getsize('mydata.csv') / 2)\n",
    "with open('mydata.csv','rb') as f:\n",
    "    f.seek(middle, 0)\n",
    "    byte_stream = f.read(os.path.getsize('mydata.csv') - middle).decode(encoding='utf-8')\n",
    "    first_newline = byte_stream.index('\\n')\n",
    "middle_newline = middle + first_newline + 1\n",
    "\n",
    "print('First chunk lines count:', first_chunk(middle_newline))\n",
    "print(\"Last chunk lines count:\", last_chunk(middle_newline))\n",
    "print(first_chunk(middle_newline) + last_chunk(middle_newline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5098965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000001\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Task 3 Question 5\n",
    "\n",
    "Check the algorithm of step (4) with multiple chunks. Define a chunk size to be 16MB.\n",
    "Write a function that process “mydata.csv “ in chunks and count number of lines for\n",
    "each chunk. For example, first chunk will be 0-16MB, second chunk 16MB-32BM, and so\n",
    "on, until the last chunk, which might be smaller.\n",
    "'''\n",
    "\n",
    "'''\n",
    "mydata.csv size is only approximately 22MB so we'll try with chunks of 4MB which is more relevant. We'll generalize\n",
    "the solution of T3Q4 to have another funtion called middle_chunk that returns both started_with_newline and\n",
    "ended_with_newline.\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "CHUNK_SIZE = 1024 * 1024 * 4\n",
    "\n",
    "FILE_SIZE = os.path.getsize('mydata.csv')\n",
    "\n",
    "def count_lines_in_chunk(seek_to, chunk_size):\n",
    "    with open('mydata.csv', 'rb') as f:\n",
    "        f.seek(seek_to, 0)\n",
    "        byte_stream = f.read(chunk_size).decode(encoding='utf-8')\n",
    "        return byte_stream.count('\\n')\n",
    "\n",
    "def get_modified_chunk_size(seek_to):\n",
    "    with open('mydata.csv', 'rb') as f:\n",
    "        f.seek(seek_to + CHUNK_SIZE, 0)\n",
    "        byte_stream = f.read(FILE_SIZE - seek_to - CHUNK_SIZE).decode(encoding='utf-8')\n",
    "        first_newline = byte_stream.index('\\n')\n",
    "    return CHUNK_SIZE + first_newline + 1\n",
    "\n",
    "total_lines = 0\n",
    "seek_to = 0\n",
    "while seek_to <= FILE_SIZE:\n",
    "    if seek_to + CHUNK_SIZE > FILE_SIZE:\n",
    "        chunk_lines = count_lines_in_chunk(seek_to, FILE_SIZE - seek_to)\n",
    "    else:\n",
    "        modified_chunk_size = get_modified_chunk_size(seek_to)\n",
    "        chunk_lines = count_lines_in_chunk(seek_to, modified_chunk_size)\n",
    "    total_lines += chunk_lines\n",
    "    seek_to += modified_chunk_size\n",
    "\n",
    "print(total_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
